{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KezH4f0blRHM"
      },
      "outputs": [],
      "source": [
        "%pip install streamlit transformers torch pyngrok accelerate\n",
        "!ngrok authtoken TOKEN_PESSOAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8bjodr01vDv"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import os\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9A95lO8tB6u",
        "outputId": "08b83547-6e26-4e87-dce8-b9fa8fd7873d"
      },
      "outputs": [],
      "source": [
        "# Configurar token do Hugging Face (se necessário)\n",
        "hf_token = 'TOKEN_PESSOAL'\n",
        "\n",
        "# Criar o código do aplicativo Streamlit\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import time\n",
        "import re\n",
        "import logging\n",
        "\n",
        "# Configuração do sistema de logs\n",
        "logging.basicConfig(\n",
        "    filename='log.txt',\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model(modelo_nome):\n",
        "    tokenizer = MarianTokenizer.from_pretrained(modelo_nome)\n",
        "    modelo = MarianMTModel.from_pretrained(modelo_nome)\n",
        "    return tokenizer, modelo\n",
        "\n",
        "def sanitize_text(texto):\n",
        "    texto = re.sub(r\"[<>]\", \"\", texto)\n",
        "    return texto.strip()\n",
        "\n",
        "def traduzir(texto, modelo_nome):\n",
        "    tokenizer, modelo = load_model(modelo_nome)\n",
        "    inputs = tokenizer([texto], return_tensors=\"pt\")\n",
        "    translated = modelo.generate(**inputs)\n",
        "    traducao = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "    return traducao\n",
        "\n",
        "st.title(\"Tradutor Multilíngue\")\n",
        "\n",
        "idiomas = {\n",
        "    \"Inglês para Espanhol\": \"Helsinki-NLP/opus-mt-en-es\",\n",
        "    \"Espanhol para Inglês\": \"Helsinki-NLP/opus-mt-es-en\",\n",
        "}\n",
        "idioma_selecionado = st.selectbox(\"Selecione o idioma de tradução:\", list(idiomas.keys()))\n",
        "\n",
        "\n",
        "texto_original = st.text_area(\n",
        "    \"Insira o texto para tradução (máximo 500 caracteres):\",\n",
        "    max_chars=500,\n",
        "    height=150\n",
        ")\n",
        "\n",
        "if st.button(\"Traduzir\"):\n",
        "    texto_original = sanitize_text(texto_original)\n",
        "    if texto_original:\n",
        "        with st.spinner(\"Traduzindo...\"):\n",
        "            try:\n",
        "                modelo_nome = idiomas[idioma_selecionado]\n",
        "                texto_traduzido = traduzir(texto_original, modelo_nome)\n",
        "\n",
        "\n",
        "                logging.info(f\"Texto Original: {texto_original}\")\n",
        "                logging.info(f\"Idioma Selecionado: {idioma_selecionado}\")\n",
        "                logging.info(f\"Texto Traduzido: {texto_traduzido}\")\n",
        "\n",
        "                st.success(\"Tradução concluída:\")\n",
        "                st.write(texto_traduzido)\n",
        "\n",
        "\n",
        "                if st.checkbox(\"A tradução foi útil?\"):\n",
        "                    st.success(\"Obrigado pelo feedback!\")\n",
        "                else:\n",
        "                    st.info(\"Por favor, nos informe como podemos melhorar.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(f\"Ocorreu um erro durante a tradução: {str(e)}\")\n",
        "                logging.error(f\"Erro: {str(e)}\")\n",
        "    else:\n",
        "        st.warning(\"Por favor, insira um texto válido para traduzir.\")\n",
        "\"\"\"\n",
        "\n",
        "# Salvar o aplicativo Streamlit em um arquivo\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "# Função para iniciar o Streamlit em segundo plano\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"app.py\"])\n",
        "\n",
        "# Criar a thread para iniciar o Streamlit\n",
        "streamlit_thread = threading.Thread(target=run_streamlit)\n",
        "streamlit_thread.start()\n",
        "\n",
        "# Aguardar um pouco para permitir que o Streamlit inicie\n",
        "time.sleep(5)\n",
        "\n",
        "# Função para iniciar o Ngrok e obter o link público\n",
        "def start_ngrok():\n",
        "    ngrok.kill()  # Reiniciar o Ngrok para evitar problemas\n",
        "    public_url = ngrok.connect(8501)  # Porta padrão do Streamlit\n",
        "    print(\"URL público:\", public_url)\n",
        "    return public_url\n",
        "\n",
        "# Obter o link do Ngrok\n",
        "public_url = start_ngrok()\n",
        "\n",
        "# Mostrar o link para acessar o Streamlit\n",
        "print(\"Clique no link para acessar o aplicativo Streamlit:\", public_url)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
